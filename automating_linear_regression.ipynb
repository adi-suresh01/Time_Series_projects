{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "498250e5-932a-43f4-b0fc-a0bd97787033",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports required\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a15cd7e5-175a-44be-a27f-2fd157320011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "Prediction before training: fn(23) = -2.740\n",
      "Epoch 1: w = 0.716, loss = 27.78076\n",
      "Epoch 11: w = 1.610, loss = 0.22310\n",
      "Epoch 21: w = 1.644, loss = 0.18624\n",
      "Epoch 31: w = 1.675, loss = 0.15549\n",
      "Epoch 41: w = 1.703, loss = 0.12982\n",
      "Epoch 51: w = 1.728, loss = 0.10839\n",
      "Epoch 61: w = 1.752, loss = 0.09049\n",
      "Epoch 71: w = 1.773, loss = 0.07555\n",
      "Epoch 81: w = 1.793, loss = 0.06308\n",
      "Epoch 91: w = 1.811, loss = 0.05266\n",
      "Epoch 101: w = 1.827, loss = 0.04397\n",
      "Epoch 111: w = 1.842, loss = 0.03671\n",
      "Epoch 121: w = 1.856, loss = 0.03065\n",
      "Epoch 131: w = 1.868, loss = 0.02559\n",
      "Epoch 141: w = 1.879, loss = 0.02136\n",
      "Epoch 151: w = 1.890, loss = 0.01784\n",
      "Epoch 161: w = 1.899, loss = 0.01489\n",
      "Epoch 171: w = 1.908, loss = 0.01243\n",
      "Epoch 181: w = 1.916, loss = 0.01038\n",
      "Epoch 191: w = 1.923, loss = 0.00867\n",
      "Epoch 201: w = 1.930, loss = 0.00724\n",
      "Epoch 211: w = 1.936, loss = 0.00604\n",
      "Epoch 221: w = 1.941, loss = 0.00504\n",
      "Epoch 231: w = 1.946, loss = 0.00421\n",
      "Epoch 241: w = 1.951, loss = 0.00352\n",
      "Epoch 251: w = 1.955, loss = 0.00294\n",
      "Epoch 261: w = 1.959, loss = 0.00245\n",
      "Epoch 271: w = 1.963, loss = 0.00205\n",
      "Epoch 281: w = 1.966, loss = 0.00171\n",
      "Epoch 291: w = 1.969, loss = 0.00143\n",
      "Epoch 301: w = 1.972, loss = 0.00119\n",
      "Epoch 311: w = 1.974, loss = 0.00099\n",
      "Epoch 321: w = 1.976, loss = 0.00083\n",
      "Epoch 331: w = 1.978, loss = 0.00069\n",
      "Epoch 341: w = 1.980, loss = 0.00058\n",
      "Epoch 351: w = 1.982, loss = 0.00048\n",
      "Epoch 361: w = 1.983, loss = 0.00040\n",
      "Epoch 371: w = 1.985, loss = 0.00034\n",
      "Epoch 381: w = 1.986, loss = 0.00028\n",
      "Epoch 391: w = 1.987, loss = 0.00023\n",
      "Epoch 401: w = 1.988, loss = 0.00020\n",
      "Epoch 411: w = 1.989, loss = 0.00016\n",
      "Epoch 421: w = 1.990, loss = 0.00014\n",
      "Epoch 431: w = 1.991, loss = 0.00011\n",
      "Epoch 441: w = 1.992, loss = 0.00010\n",
      "Epoch 451: w = 1.993, loss = 0.00008\n",
      "Epoch 461: w = 1.993, loss = 0.00007\n",
      "Epoch 471: w = 1.994, loss = 0.00006\n",
      "Epoch 481: w = 1.994, loss = 0.00005\n",
      "Epoch 491: w = 1.995, loss = 0.00004\n",
      "Epoch 501: w = 1.995, loss = 0.00003\n",
      "Epoch 511: w = 1.996, loss = 0.00003\n",
      "Epoch 521: w = 1.996, loss = 0.00002\n",
      "Epoch 531: w = 1.996, loss = 0.00002\n",
      "Epoch 541: w = 1.997, loss = 0.00002\n",
      "Epoch 551: w = 1.997, loss = 0.00001\n",
      "Epoch 561: w = 1.997, loss = 0.00001\n",
      "Epoch 571: w = 1.998, loss = 0.00001\n",
      "Epoch 581: w = 1.998, loss = 0.00001\n",
      "Epoch 591: w = 1.998, loss = 0.00001\n",
      "Epoch 601: w = 1.998, loss = 0.00001\n",
      "Epoch 611: w = 1.998, loss = 0.00000\n",
      "Epoch 621: w = 1.998, loss = 0.00000\n",
      "Epoch 631: w = 1.999, loss = 0.00000\n",
      "Epoch 641: w = 1.999, loss = 0.00000\n",
      "Epoch 651: w = 1.999, loss = 0.00000\n",
      "Epoch 661: w = 1.999, loss = 0.00000\n",
      "Epoch 671: w = 1.999, loss = 0.00000\n",
      "Epoch 681: w = 1.999, loss = 0.00000\n",
      "Epoch 691: w = 1.999, loss = 0.00000\n",
      "Epoch 701: w = 1.999, loss = 0.00000\n",
      "Epoch 711: w = 1.999, loss = 0.00000\n",
      "Epoch 721: w = 1.999, loss = 0.00000\n",
      "Epoch 731: w = 1.999, loss = 0.00000\n",
      "Epoch 741: w = 1.999, loss = 0.00000\n",
      "Epoch 751: w = 2.000, loss = 0.00000\n",
      "Epoch 761: w = 2.000, loss = 0.00000\n",
      "Epoch 771: w = 2.000, loss = 0.00000\n",
      "Epoch 781: w = 2.000, loss = 0.00000\n",
      "Epoch 791: w = 2.000, loss = 0.00000\n",
      "Epoch 801: w = 2.000, loss = 0.00000\n",
      "Epoch 811: w = 2.000, loss = 0.00000\n",
      "Epoch 821: w = 2.000, loss = 0.00000\n",
      "Epoch 831: w = 2.000, loss = 0.00000\n",
      "Epoch 841: w = 2.000, loss = 0.00000\n",
      "Epoch 851: w = 2.000, loss = 0.00000\n",
      "Epoch 861: w = 2.000, loss = 0.00000\n",
      "Epoch 871: w = 2.000, loss = 0.00000\n",
      "Epoch 881: w = 2.000, loss = 0.00000\n",
      "Epoch 891: w = 2.000, loss = 0.00000\n",
      "Epoch 901: w = 2.000, loss = 0.00000\n",
      "Epoch 911: w = 2.000, loss = 0.00000\n",
      "Epoch 921: w = 2.000, loss = 0.00000\n",
      "Epoch 931: w = 2.000, loss = 0.00000\n",
      "Epoch 941: w = 2.000, loss = 0.00000\n",
      "Epoch 951: w = 2.000, loss = 0.00000\n",
      "Epoch 961: w = 2.000, loss = 0.00000\n",
      "Epoch 971: w = 2.000, loss = 0.00000\n",
      "Epoch 981: w = 2.000, loss = 0.00000\n",
      "Epoch 991: w = 2.000, loss = 0.00000\n",
      "Prediction after training: fn(23) = 45.999\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
    "y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
    "\n",
    "x_test = torch .tensor([23], dtype=torch.float32)\n",
    "\n",
    "n_samples, n_features = x.shape\n",
    "print(n_samples, n_features)\n",
    "\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "print(f\"Prediction before training: fn(23) = {model(x_test).item():.3f}\")\n",
    "\n",
    "learning_rate = 0.03\n",
    "n_iters = 1000\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "optimizer =  torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    y_pred = model(x)\n",
    "\n",
    "    l = loss(y, y_pred)\n",
    "\n",
    "    l.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        [w, b] = model.parameters()\n",
    "        print(f\"Epoch {epoch+1}: w = {w[0][0].item():.3f}, loss = {l:.5f}\")\n",
    "\n",
    "print(f\"Prediction after training: fn(23) = {model(x_test).item():.3f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c20e8110-7978-4e1a-8214-9db71e6dd51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 13\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "binary_class = datasets.load_wine()\n",
    "\n",
    "X, y = binary_class.data, binary_class.target\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "print(n_samples, n_features)\n",
    "\n",
    "input_size = n_samples\n",
    "output_size = n_features\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)\n",
    "\n",
    "X_train = torch.from_numpy(X_train.astype(np.float64))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float64))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float64))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float64))\n",
    "\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "\n",
    "\n",
    "model = nn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fefaea-735c-441e-8d20-1066f4687cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
